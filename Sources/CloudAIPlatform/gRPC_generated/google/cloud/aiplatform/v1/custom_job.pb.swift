// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/aiplatform/v1/custom_job.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Represents a job that runs custom workloads such as a Docker container or a
/// Python package. A CustomJob can have multiple worker pools and each worker
/// pool can have its own machine and input spec. A CustomJob will be cleaned up
/// once the job enters terminal state (failed or succeeded).
public struct Google_Cloud_Aiplatform_V1_CustomJob: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Resource name of a CustomJob.
  public var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// Required. The display name of the CustomJob.
  /// The name can be up to 128 characters long and can consist of any UTF-8
  /// characters.
  public var displayName: String {
    get {return _storage._displayName}
    set {_uniqueStorage()._displayName = newValue}
  }

  /// Required. Job spec.
  public var jobSpec: Google_Cloud_Aiplatform_V1_CustomJobSpec {
    get {return _storage._jobSpec ?? Google_Cloud_Aiplatform_V1_CustomJobSpec()}
    set {_uniqueStorage()._jobSpec = newValue}
  }
  /// Returns true if `jobSpec` has been explicitly set.
  public var hasJobSpec: Bool {return _storage._jobSpec != nil}
  /// Clears the value of `jobSpec`. Subsequent reads from it will return its default value.
  public mutating func clearJobSpec() {_uniqueStorage()._jobSpec = nil}

  /// Output only. The detailed state of the job.
  public var state: Google_Cloud_Aiplatform_V1_JobState {
    get {return _storage._state}
    set {_uniqueStorage()._state = newValue}
  }

  /// Output only. Time when the CustomJob was created.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return _storage._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {_uniqueStorage()._createTime = nil}

  /// Output only. Time when the CustomJob for the first time entered the
  /// `JOB_STATE_RUNNING` state.
  public var startTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._startTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._startTime = newValue}
  }
  /// Returns true if `startTime` has been explicitly set.
  public var hasStartTime: Bool {return _storage._startTime != nil}
  /// Clears the value of `startTime`. Subsequent reads from it will return its default value.
  public mutating func clearStartTime() {_uniqueStorage()._startTime = nil}

  /// Output only. Time when the CustomJob entered any of the following states:
  /// `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.
  public var endTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._endTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._endTime = newValue}
  }
  /// Returns true if `endTime` has been explicitly set.
  public var hasEndTime: Bool {return _storage._endTime != nil}
  /// Clears the value of `endTime`. Subsequent reads from it will return its default value.
  public mutating func clearEndTime() {_uniqueStorage()._endTime = nil}

  /// Output only. Time when the CustomJob was most recently updated.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// Output only. Only populated when job's state is `JOB_STATE_FAILED` or
  /// `JOB_STATE_CANCELLED`.
  public var error: Google_Rpc_Status {
    get {return _storage._error ?? Google_Rpc_Status()}
    set {_uniqueStorage()._error = newValue}
  }
  /// Returns true if `error` has been explicitly set.
  public var hasError: Bool {return _storage._error != nil}
  /// Clears the value of `error`. Subsequent reads from it will return its default value.
  public mutating func clearError() {_uniqueStorage()._error = nil}

  /// The labels with user-defined metadata to organize CustomJobs.
  ///
  /// Label keys and values can be no longer than 64 characters
  /// (Unicode codepoints), can only contain lowercase letters, numeric
  /// characters, underscores and dashes. International characters are allowed.
  ///
  /// See https://goo.gl/xmQnxf for more information and examples of labels.
  public var labels: Dictionary<String,String> {
    get {return _storage._labels}
    set {_uniqueStorage()._labels = newValue}
  }

  /// Customer-managed encryption key options for a CustomJob. If this is set,
  /// then all resources created by the CustomJob will be encrypted with the
  /// provided encryption key.
  public var encryptionSpec: Google_Cloud_Aiplatform_V1_EncryptionSpec {
    get {return _storage._encryptionSpec ?? Google_Cloud_Aiplatform_V1_EncryptionSpec()}
    set {_uniqueStorage()._encryptionSpec = newValue}
  }
  /// Returns true if `encryptionSpec` has been explicitly set.
  public var hasEncryptionSpec: Bool {return _storage._encryptionSpec != nil}
  /// Clears the value of `encryptionSpec`. Subsequent reads from it will return its default value.
  public mutating func clearEncryptionSpec() {_uniqueStorage()._encryptionSpec = nil}

  /// Output only. URIs for accessing [interactive
  /// shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
  /// (one URI for each training node). Only available if
  /// [job_spec.enable_web_access][google.cloud.aiplatform.v1.CustomJobSpec.enable_web_access]
  /// is `true`.
  ///
  /// The keys are names of each node in the training job; for example,
  /// `workerpool0-0` for the primary node, `workerpool1-0` for the first node in
  /// the second worker pool, and `workerpool1-1` for the second node in the
  /// second worker pool.
  ///
  /// The values are the URIs for each node's interactive shell.
  public var webAccessUris: Dictionary<String,String> {
    get {return _storage._webAccessUris}
    set {_uniqueStorage()._webAccessUris = newValue}
  }

  /// Output only. Reserved for future use.
  public var satisfiesPzs: Bool {
    get {return _storage._satisfiesPzs}
    set {_uniqueStorage()._satisfiesPzs = newValue}
  }

  /// Output only. Reserved for future use.
  public var satisfiesPzi: Bool {
    get {return _storage._satisfiesPzi}
    set {_uniqueStorage()._satisfiesPzi = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Represents the spec of a CustomJob.
public struct Google_Cloud_Aiplatform_V1_CustomJobSpec: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Optional. The ID of the PersistentResource in the same Project and Location
  /// which to run
  ///
  /// If this is specified, the job will be run on existing machines held by the
  /// PersistentResource instead of on-demand short-live machines.
  /// The network and CMEK configs on the job should be consistent with those on
  /// the PersistentResource, otherwise, the job will be rejected.
  public var persistentResourceID: String {
    get {return _storage._persistentResourceID}
    set {_uniqueStorage()._persistentResourceID = newValue}
  }

  /// Required. The spec of the worker pools including machine type and Docker
  /// image. All worker pools except the first one are optional and can be
  /// skipped by providing an empty value.
  public var workerPoolSpecs: [Google_Cloud_Aiplatform_V1_WorkerPoolSpec] {
    get {return _storage._workerPoolSpecs}
    set {_uniqueStorage()._workerPoolSpecs = newValue}
  }

  /// Scheduling options for a CustomJob.
  public var scheduling: Google_Cloud_Aiplatform_V1_Scheduling {
    get {return _storage._scheduling ?? Google_Cloud_Aiplatform_V1_Scheduling()}
    set {_uniqueStorage()._scheduling = newValue}
  }
  /// Returns true if `scheduling` has been explicitly set.
  public var hasScheduling: Bool {return _storage._scheduling != nil}
  /// Clears the value of `scheduling`. Subsequent reads from it will return its default value.
  public mutating func clearScheduling() {_uniqueStorage()._scheduling = nil}

  /// Specifies the service account for workload run-as account.
  /// Users submitting jobs must have act-as permission on this run-as account.
  /// If unspecified, the [Vertex AI Custom Code Service
  /// Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents)
  /// for the CustomJob's project is used.
  public var serviceAccount: String {
    get {return _storage._serviceAccount}
    set {_uniqueStorage()._serviceAccount = newValue}
  }

  /// Optional. The full name of the Compute Engine
  /// [network](/compute/docs/networks-and-firewalls#networks) to which the Job
  /// should be peered. For example, `projects/12345/global/networks/myVPC`.
  /// [Format](/compute/docs/reference/rest/v1/networks/insert)
  /// is of the form `projects/{project}/global/networks/{network}`.
  /// Where {project} is a project number, as in `12345`, and {network} is a
  /// network name.
  ///
  /// To specify this field, you must have already [configured VPC Network
  /// Peering for Vertex
  /// AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering).
  ///
  /// If this field is left unspecified, the job is not peered with any network.
  public var network: String {
    get {return _storage._network}
    set {_uniqueStorage()._network = newValue}
  }

  /// Optional. A list of names for the reserved ip ranges under the VPC network
  /// that can be used for this job.
  ///
  /// If set, we will deploy the job within the provided ip ranges. Otherwise,
  /// the job will be deployed to any ip ranges under the provided VPC
  /// network.
  ///
  /// Example: ['vertex-ai-ip-range'].
  public var reservedIpRanges: [String] {
    get {return _storage._reservedIpRanges}
    set {_uniqueStorage()._reservedIpRanges = newValue}
  }

  /// The Cloud Storage location to store the output of this CustomJob or
  /// HyperparameterTuningJob. For HyperparameterTuningJob,
  /// the baseOutputDirectory of
  /// each child CustomJob backing a Trial is set to a subdirectory of name
  /// [id][google.cloud.aiplatform.v1.Trial.id] under its parent
  /// HyperparameterTuningJob's baseOutputDirectory.
  ///
  /// The following Vertex AI environment variables will be passed to
  /// containers or python modules when this field is set:
  ///
  ///   For CustomJob:
  ///
  ///   * AIP_MODEL_DIR = `<base_output_directory>/model/`
  ///   * AIP_CHECKPOINT_DIR = `<base_output_directory>/checkpoints/`
  ///   * AIP_TENSORBOARD_LOG_DIR = `<base_output_directory>/logs/`
  ///
  ///   For CustomJob backing a Trial of HyperparameterTuningJob:
  ///
  ///   * AIP_MODEL_DIR = `<base_output_directory>/<trial_id>/model/`
  ///   * AIP_CHECKPOINT_DIR = `<base_output_directory>/<trial_id>/checkpoints/`
  ///   * AIP_TENSORBOARD_LOG_DIR = `<base_output_directory>/<trial_id>/logs/`
  public var baseOutputDirectory: Google_Cloud_Aiplatform_V1_GcsDestination {
    get {return _storage._baseOutputDirectory ?? Google_Cloud_Aiplatform_V1_GcsDestination()}
    set {_uniqueStorage()._baseOutputDirectory = newValue}
  }
  /// Returns true if `baseOutputDirectory` has been explicitly set.
  public var hasBaseOutputDirectory: Bool {return _storage._baseOutputDirectory != nil}
  /// Clears the value of `baseOutputDirectory`. Subsequent reads from it will return its default value.
  public mutating func clearBaseOutputDirectory() {_uniqueStorage()._baseOutputDirectory = nil}

  /// The ID of the location to store protected artifacts. e.g. us-central1.
  /// Populate only when the location is different than CustomJob location.
  /// List of supported locations:
  /// https://cloud.google.com/vertex-ai/docs/general/locations
  public var protectedArtifactLocationID: String {
    get {return _storage._protectedArtifactLocationID}
    set {_uniqueStorage()._protectedArtifactLocationID = newValue}
  }

  /// Optional. The name of a Vertex AI
  /// [Tensorboard][google.cloud.aiplatform.v1.Tensorboard] resource to which
  /// this CustomJob will upload Tensorboard logs. Format:
  /// `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
  public var tensorboard: String {
    get {return _storage._tensorboard}
    set {_uniqueStorage()._tensorboard = newValue}
  }

  /// Optional. Whether you want Vertex AI to enable [interactive shell
  /// access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
  /// to training containers.
  ///
  /// If set to `true`, you can access interactive shells at the URIs given
  /// by
  /// [CustomJob.web_access_uris][google.cloud.aiplatform.v1.CustomJob.web_access_uris]
  /// or
  /// [Trial.web_access_uris][google.cloud.aiplatform.v1.Trial.web_access_uris]
  /// (within
  /// [HyperparameterTuningJob.trials][google.cloud.aiplatform.v1.HyperparameterTuningJob.trials]).
  public var enableWebAccess: Bool {
    get {return _storage._enableWebAccess}
    set {_uniqueStorage()._enableWebAccess = newValue}
  }

  /// Optional. Whether you want Vertex AI to enable access to the customized
  /// dashboard in training chief container.
  ///
  /// If set to `true`, you can access the dashboard at the URIs given
  /// by
  /// [CustomJob.web_access_uris][google.cloud.aiplatform.v1.CustomJob.web_access_uris]
  /// or
  /// [Trial.web_access_uris][google.cloud.aiplatform.v1.Trial.web_access_uris]
  /// (within
  /// [HyperparameterTuningJob.trials][google.cloud.aiplatform.v1.HyperparameterTuningJob.trials]).
  public var enableDashboardAccess: Bool {
    get {return _storage._enableDashboardAccess}
    set {_uniqueStorage()._enableDashboardAccess = newValue}
  }

  /// Optional. The Experiment associated with this job.
  /// Format:
  /// `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`
  public var experiment: String {
    get {return _storage._experiment}
    set {_uniqueStorage()._experiment = newValue}
  }

  /// Optional. The Experiment Run associated with this job.
  /// Format:
  /// `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`
  public var experimentRun: String {
    get {return _storage._experimentRun}
    set {_uniqueStorage()._experimentRun = newValue}
  }

  /// Optional. The name of the Model resources for which to generate a mapping
  /// to artifact URIs. Applicable only to some of the Google-provided custom
  /// jobs. Format: `projects/{project}/locations/{location}/models/{model}`
  ///
  /// In order to retrieve a specific version of the model, also provide
  /// the version ID or version alias.
  ///   Example: `projects/{project}/locations/{location}/models/{model}@2`
  ///              or
  ///            `projects/{project}/locations/{location}/models/{model}@golden`
  /// If no version ID or alias is specified, the "default" version will be
  /// returned. The "default" version alias is created for the first version of
  /// the model, and can be moved to other versions later on. There will be
  /// exactly one default version.
  public var models: [String] {
    get {return _storage._models}
    set {_uniqueStorage()._models = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Represents the spec of a worker pool in a job.
public struct Google_Cloud_Aiplatform_V1_WorkerPoolSpec: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The custom task to be executed in this worker pool.
  public var task: Google_Cloud_Aiplatform_V1_WorkerPoolSpec.OneOf_Task? = nil

  /// The custom container task.
  public var containerSpec: Google_Cloud_Aiplatform_V1_ContainerSpec {
    get {
      if case .containerSpec(let v)? = task {return v}
      return Google_Cloud_Aiplatform_V1_ContainerSpec()
    }
    set {task = .containerSpec(newValue)}
  }

  /// The Python packaged task.
  public var pythonPackageSpec: Google_Cloud_Aiplatform_V1_PythonPackageSpec {
    get {
      if case .pythonPackageSpec(let v)? = task {return v}
      return Google_Cloud_Aiplatform_V1_PythonPackageSpec()
    }
    set {task = .pythonPackageSpec(newValue)}
  }

  /// Optional. Immutable. The specification of a single machine.
  public var machineSpec: Google_Cloud_Aiplatform_V1_MachineSpec {
    get {return _machineSpec ?? Google_Cloud_Aiplatform_V1_MachineSpec()}
    set {_machineSpec = newValue}
  }
  /// Returns true if `machineSpec` has been explicitly set.
  public var hasMachineSpec: Bool {return self._machineSpec != nil}
  /// Clears the value of `machineSpec`. Subsequent reads from it will return its default value.
  public mutating func clearMachineSpec() {self._machineSpec = nil}

  /// Optional. The number of worker replicas to use for this worker pool.
  public var replicaCount: Int64 = 0

  /// Optional. List of NFS mount spec.
  public var nfsMounts: [Google_Cloud_Aiplatform_V1_NfsMount] = []

  /// Disk spec.
  public var diskSpec: Google_Cloud_Aiplatform_V1_DiskSpec {
    get {return _diskSpec ?? Google_Cloud_Aiplatform_V1_DiskSpec()}
    set {_diskSpec = newValue}
  }
  /// Returns true if `diskSpec` has been explicitly set.
  public var hasDiskSpec: Bool {return self._diskSpec != nil}
  /// Clears the value of `diskSpec`. Subsequent reads from it will return its default value.
  public mutating func clearDiskSpec() {self._diskSpec = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The custom task to be executed in this worker pool.
  public enum OneOf_Task: Equatable, Sendable {
    /// The custom container task.
    case containerSpec(Google_Cloud_Aiplatform_V1_ContainerSpec)
    /// The Python packaged task.
    case pythonPackageSpec(Google_Cloud_Aiplatform_V1_PythonPackageSpec)

  }

  public init() {}

  fileprivate var _machineSpec: Google_Cloud_Aiplatform_V1_MachineSpec? = nil
  fileprivate var _diskSpec: Google_Cloud_Aiplatform_V1_DiskSpec? = nil
}

/// The spec of a Container.
public struct Google_Cloud_Aiplatform_V1_ContainerSpec: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The URI of a container image in the Container Registry that is to
  /// be run on each worker replica.
  public var imageUri: String = String()

  /// The command to be invoked when the container is started.
  /// It overrides the entrypoint instruction in Dockerfile when provided.
  public var command: [String] = []

  /// The arguments to be passed when starting the container.
  public var args: [String] = []

  /// Environment variables to be passed to the container.
  /// Maximum limit is 100.
  public var env: [Google_Cloud_Aiplatform_V1_EnvVar] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The spec of a Python packaged code.
public struct Google_Cloud_Aiplatform_V1_PythonPackageSpec: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The URI of a container image in Artifact Registry that will run
  /// the provided Python package. Vertex AI provides a wide range of executor
  /// images with pre-installed packages to meet users' various use cases. See
  /// the list of [pre-built containers for
  /// training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers).
  /// You must use an image from this list.
  public var executorImageUri: String = String()

  /// Required. The Google Cloud Storage location of the Python package files
  /// which are the training program and its dependent packages. The maximum
  /// number of package URIs is 100.
  public var packageUris: [String] = []

  /// Required. The Python module name to run after installing the packages.
  public var pythonModule: String = String()

  /// Command line arguments to be passed to the Python task.
  public var args: [String] = []

  /// Environment variables to be passed to the python module.
  /// Maximum limit is 100.
  public var env: [Google_Cloud_Aiplatform_V1_EnvVar] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// All parameters related to queuing and scheduling of custom jobs.
public struct Google_Cloud_Aiplatform_V1_Scheduling: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The maximum job running time. The default is 7 days.
  public var timeout: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _timeout ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_timeout = newValue}
  }
  /// Returns true if `timeout` has been explicitly set.
  public var hasTimeout: Bool {return self._timeout != nil}
  /// Clears the value of `timeout`. Subsequent reads from it will return its default value.
  public mutating func clearTimeout() {self._timeout = nil}

  /// Restarts the entire CustomJob if a worker gets restarted.
  /// This feature can be used by distributed training jobs that are not
  /// resilient to workers leaving and joining a job.
  public var restartJobOnWorkerRestart: Bool = false

  /// Optional. This determines which type of scheduling strategy to use.
  public var strategy: Google_Cloud_Aiplatform_V1_Scheduling.Strategy = .unspecified

  /// Optional. Indicates if the job should retry for internal errors after the
  /// job starts running. If true, overrides
  /// `Scheduling.restart_job_on_worker_restart` to false.
  public var disableRetries: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Optional. This determines which type of scheduling strategy to use. Right
  /// now users have two options such as STANDARD which will use regular on
  /// demand resources to schedule the job, the other is SPOT which would
  /// leverage spot resources alongwith regular resources to schedule
  /// the job.
  public enum Strategy: SwiftProtobuf.Enum, Swift.CaseIterable {
    public typealias RawValue = Int

    /// Strategy will default to STANDARD.
    case unspecified // = 0

    /// Regular on-demand provisioning strategy.
    ///
    /// NOTE: This enum value was marked as deprecated in the .proto file
    case onDemand // = 1

    /// Low cost by making potential use of spot resources.
    ///
    /// NOTE: This enum value was marked as deprecated in the .proto file
    case lowCost // = 2

    /// Standard provisioning strategy uses regular on-demand resources.
    case standard // = 3

    /// Spot provisioning strategy uses spot resources.
    case spot // = 4
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .onDemand
      case 2: self = .lowCost
      case 3: self = .standard
      case 4: self = .spot
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .onDemand: return 1
      case .lowCost: return 2
      case .standard: return 3
      case .spot: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    public static let allCases: [Google_Cloud_Aiplatform_V1_Scheduling.Strategy] = [
      .unspecified,
      .onDemand,
      .lowCost,
      .standard,
      .spot,
    ]

  }

  public init() {}

  fileprivate var _timeout: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.aiplatform.v1"

extension Google_Cloud_Aiplatform_V1_CustomJob: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CustomJob"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "display_name"),
    4: .standard(proto: "job_spec"),
    5: .same(proto: "state"),
    6: .standard(proto: "create_time"),
    7: .standard(proto: "start_time"),
    8: .standard(proto: "end_time"),
    9: .standard(proto: "update_time"),
    10: .same(proto: "error"),
    11: .same(proto: "labels"),
    12: .standard(proto: "encryption_spec"),
    16: .standard(proto: "web_access_uris"),
    18: .standard(proto: "satisfies_pzs"),
    19: .standard(proto: "satisfies_pzi"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _displayName: String = String()
    var _jobSpec: Google_Cloud_Aiplatform_V1_CustomJobSpec? = nil
    var _state: Google_Cloud_Aiplatform_V1_JobState = .unspecified
    var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _startTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _endTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _error: Google_Rpc_Status? = nil
    var _labels: Dictionary<String,String> = [:]
    var _encryptionSpec: Google_Cloud_Aiplatform_V1_EncryptionSpec? = nil
    var _webAccessUris: Dictionary<String,String> = [:]
    var _satisfiesPzs: Bool = false
    var _satisfiesPzi: Bool = false

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _displayName = source._displayName
      _jobSpec = source._jobSpec
      _state = source._state
      _createTime = source._createTime
      _startTime = source._startTime
      _endTime = source._endTime
      _updateTime = source._updateTime
      _error = source._error
      _labels = source._labels
      _encryptionSpec = source._encryptionSpec
      _webAccessUris = source._webAccessUris
      _satisfiesPzs = source._satisfiesPzs
      _satisfiesPzi = source._satisfiesPzi
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._displayName) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._jobSpec) }()
        case 5: try { try decoder.decodeSingularEnumField(value: &_storage._state) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._createTime) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._startTime) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._endTime) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._error) }()
        case 11: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._labels) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._encryptionSpec) }()
        case 16: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._webAccessUris) }()
        case 18: try { try decoder.decodeSingularBoolField(value: &_storage._satisfiesPzs) }()
        case 19: try { try decoder.decodeSingularBoolField(value: &_storage._satisfiesPzi) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if !_storage._displayName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._displayName, fieldNumber: 2)
      }
      try { if let v = _storage._jobSpec {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      if _storage._state != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._state, fieldNumber: 5)
      }
      try { if let v = _storage._createTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._startTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._endTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._error {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
      if !_storage._labels.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._labels, fieldNumber: 11)
      }
      try { if let v = _storage._encryptionSpec {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      } }()
      if !_storage._webAccessUris.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._webAccessUris, fieldNumber: 16)
      }
      if _storage._satisfiesPzs != false {
        try visitor.visitSingularBoolField(value: _storage._satisfiesPzs, fieldNumber: 18)
      }
      if _storage._satisfiesPzi != false {
        try visitor.visitSingularBoolField(value: _storage._satisfiesPzi, fieldNumber: 19)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_CustomJob, rhs: Google_Cloud_Aiplatform_V1_CustomJob) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._name != rhs_storage._name {return false}
        if _storage._displayName != rhs_storage._displayName {return false}
        if _storage._jobSpec != rhs_storage._jobSpec {return false}
        if _storage._state != rhs_storage._state {return false}
        if _storage._createTime != rhs_storage._createTime {return false}
        if _storage._startTime != rhs_storage._startTime {return false}
        if _storage._endTime != rhs_storage._endTime {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._error != rhs_storage._error {return false}
        if _storage._labels != rhs_storage._labels {return false}
        if _storage._encryptionSpec != rhs_storage._encryptionSpec {return false}
        if _storage._webAccessUris != rhs_storage._webAccessUris {return false}
        if _storage._satisfiesPzs != rhs_storage._satisfiesPzs {return false}
        if _storage._satisfiesPzi != rhs_storage._satisfiesPzi {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_CustomJobSpec: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CustomJobSpec"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    14: .standard(proto: "persistent_resource_id"),
    1: .standard(proto: "worker_pool_specs"),
    3: .same(proto: "scheduling"),
    4: .standard(proto: "service_account"),
    5: .same(proto: "network"),
    13: .standard(proto: "reserved_ip_ranges"),
    6: .standard(proto: "base_output_directory"),
    19: .standard(proto: "protected_artifact_location_id"),
    7: .same(proto: "tensorboard"),
    10: .standard(proto: "enable_web_access"),
    16: .standard(proto: "enable_dashboard_access"),
    17: .same(proto: "experiment"),
    18: .standard(proto: "experiment_run"),
    20: .same(proto: "models"),
  ]

  fileprivate class _StorageClass {
    var _persistentResourceID: String = String()
    var _workerPoolSpecs: [Google_Cloud_Aiplatform_V1_WorkerPoolSpec] = []
    var _scheduling: Google_Cloud_Aiplatform_V1_Scheduling? = nil
    var _serviceAccount: String = String()
    var _network: String = String()
    var _reservedIpRanges: [String] = []
    var _baseOutputDirectory: Google_Cloud_Aiplatform_V1_GcsDestination? = nil
    var _protectedArtifactLocationID: String = String()
    var _tensorboard: String = String()
    var _enableWebAccess: Bool = false
    var _enableDashboardAccess: Bool = false
    var _experiment: String = String()
    var _experimentRun: String = String()
    var _models: [String] = []

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _persistentResourceID = source._persistentResourceID
      _workerPoolSpecs = source._workerPoolSpecs
      _scheduling = source._scheduling
      _serviceAccount = source._serviceAccount
      _network = source._network
      _reservedIpRanges = source._reservedIpRanges
      _baseOutputDirectory = source._baseOutputDirectory
      _protectedArtifactLocationID = source._protectedArtifactLocationID
      _tensorboard = source._tensorboard
      _enableWebAccess = source._enableWebAccess
      _enableDashboardAccess = source._enableDashboardAccess
      _experiment = source._experiment
      _experimentRun = source._experimentRun
      _models = source._models
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeRepeatedMessageField(value: &_storage._workerPoolSpecs) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._scheduling) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._serviceAccount) }()
        case 5: try { try decoder.decodeSingularStringField(value: &_storage._network) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._baseOutputDirectory) }()
        case 7: try { try decoder.decodeSingularStringField(value: &_storage._tensorboard) }()
        case 10: try { try decoder.decodeSingularBoolField(value: &_storage._enableWebAccess) }()
        case 13: try { try decoder.decodeRepeatedStringField(value: &_storage._reservedIpRanges) }()
        case 14: try { try decoder.decodeSingularStringField(value: &_storage._persistentResourceID) }()
        case 16: try { try decoder.decodeSingularBoolField(value: &_storage._enableDashboardAccess) }()
        case 17: try { try decoder.decodeSingularStringField(value: &_storage._experiment) }()
        case 18: try { try decoder.decodeSingularStringField(value: &_storage._experimentRun) }()
        case 19: try { try decoder.decodeSingularStringField(value: &_storage._protectedArtifactLocationID) }()
        case 20: try { try decoder.decodeRepeatedStringField(value: &_storage._models) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._workerPoolSpecs.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._workerPoolSpecs, fieldNumber: 1)
      }
      try { if let v = _storage._scheduling {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      } }()
      if !_storage._serviceAccount.isEmpty {
        try visitor.visitSingularStringField(value: _storage._serviceAccount, fieldNumber: 4)
      }
      if !_storage._network.isEmpty {
        try visitor.visitSingularStringField(value: _storage._network, fieldNumber: 5)
      }
      try { if let v = _storage._baseOutputDirectory {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      if !_storage._tensorboard.isEmpty {
        try visitor.visitSingularStringField(value: _storage._tensorboard, fieldNumber: 7)
      }
      if _storage._enableWebAccess != false {
        try visitor.visitSingularBoolField(value: _storage._enableWebAccess, fieldNumber: 10)
      }
      if !_storage._reservedIpRanges.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._reservedIpRanges, fieldNumber: 13)
      }
      if !_storage._persistentResourceID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._persistentResourceID, fieldNumber: 14)
      }
      if _storage._enableDashboardAccess != false {
        try visitor.visitSingularBoolField(value: _storage._enableDashboardAccess, fieldNumber: 16)
      }
      if !_storage._experiment.isEmpty {
        try visitor.visitSingularStringField(value: _storage._experiment, fieldNumber: 17)
      }
      if !_storage._experimentRun.isEmpty {
        try visitor.visitSingularStringField(value: _storage._experimentRun, fieldNumber: 18)
      }
      if !_storage._protectedArtifactLocationID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._protectedArtifactLocationID, fieldNumber: 19)
      }
      if !_storage._models.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._models, fieldNumber: 20)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_CustomJobSpec, rhs: Google_Cloud_Aiplatform_V1_CustomJobSpec) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._persistentResourceID != rhs_storage._persistentResourceID {return false}
        if _storage._workerPoolSpecs != rhs_storage._workerPoolSpecs {return false}
        if _storage._scheduling != rhs_storage._scheduling {return false}
        if _storage._serviceAccount != rhs_storage._serviceAccount {return false}
        if _storage._network != rhs_storage._network {return false}
        if _storage._reservedIpRanges != rhs_storage._reservedIpRanges {return false}
        if _storage._baseOutputDirectory != rhs_storage._baseOutputDirectory {return false}
        if _storage._protectedArtifactLocationID != rhs_storage._protectedArtifactLocationID {return false}
        if _storage._tensorboard != rhs_storage._tensorboard {return false}
        if _storage._enableWebAccess != rhs_storage._enableWebAccess {return false}
        if _storage._enableDashboardAccess != rhs_storage._enableDashboardAccess {return false}
        if _storage._experiment != rhs_storage._experiment {return false}
        if _storage._experimentRun != rhs_storage._experimentRun {return false}
        if _storage._models != rhs_storage._models {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_WorkerPoolSpec: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".WorkerPoolSpec"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    6: .standard(proto: "container_spec"),
    7: .standard(proto: "python_package_spec"),
    1: .standard(proto: "machine_spec"),
    2: .standard(proto: "replica_count"),
    4: .standard(proto: "nfs_mounts"),
    5: .standard(proto: "disk_spec"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._machineSpec) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.replicaCount) }()
      case 4: try { try decoder.decodeRepeatedMessageField(value: &self.nfsMounts) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._diskSpec) }()
      case 6: try {
        var v: Google_Cloud_Aiplatform_V1_ContainerSpec?
        var hadOneofValue = false
        if let current = self.task {
          hadOneofValue = true
          if case .containerSpec(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.task = .containerSpec(v)
        }
      }()
      case 7: try {
        var v: Google_Cloud_Aiplatform_V1_PythonPackageSpec?
        var hadOneofValue = false
        if let current = self.task {
          hadOneofValue = true
          if case .pythonPackageSpec(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.task = .pythonPackageSpec(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._machineSpec {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.replicaCount != 0 {
      try visitor.visitSingularInt64Field(value: self.replicaCount, fieldNumber: 2)
    }
    if !self.nfsMounts.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.nfsMounts, fieldNumber: 4)
    }
    try { if let v = self._diskSpec {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    switch self.task {
    case .containerSpec?: try {
      guard case .containerSpec(let v)? = self.task else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case .pythonPackageSpec?: try {
      guard case .pythonPackageSpec(let v)? = self.task else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_WorkerPoolSpec, rhs: Google_Cloud_Aiplatform_V1_WorkerPoolSpec) -> Bool {
    if lhs.task != rhs.task {return false}
    if lhs._machineSpec != rhs._machineSpec {return false}
    if lhs.replicaCount != rhs.replicaCount {return false}
    if lhs.nfsMounts != rhs.nfsMounts {return false}
    if lhs._diskSpec != rhs._diskSpec {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_ContainerSpec: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ContainerSpec"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "image_uri"),
    2: .same(proto: "command"),
    3: .same(proto: "args"),
    4: .same(proto: "env"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.imageUri) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.command) }()
      case 3: try { try decoder.decodeRepeatedStringField(value: &self.args) }()
      case 4: try { try decoder.decodeRepeatedMessageField(value: &self.env) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.imageUri.isEmpty {
      try visitor.visitSingularStringField(value: self.imageUri, fieldNumber: 1)
    }
    if !self.command.isEmpty {
      try visitor.visitRepeatedStringField(value: self.command, fieldNumber: 2)
    }
    if !self.args.isEmpty {
      try visitor.visitRepeatedStringField(value: self.args, fieldNumber: 3)
    }
    if !self.env.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.env, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_ContainerSpec, rhs: Google_Cloud_Aiplatform_V1_ContainerSpec) -> Bool {
    if lhs.imageUri != rhs.imageUri {return false}
    if lhs.command != rhs.command {return false}
    if lhs.args != rhs.args {return false}
    if lhs.env != rhs.env {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_PythonPackageSpec: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".PythonPackageSpec"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "executor_image_uri"),
    2: .standard(proto: "package_uris"),
    3: .standard(proto: "python_module"),
    4: .same(proto: "args"),
    5: .same(proto: "env"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.executorImageUri) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.packageUris) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.pythonModule) }()
      case 4: try { try decoder.decodeRepeatedStringField(value: &self.args) }()
      case 5: try { try decoder.decodeRepeatedMessageField(value: &self.env) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.executorImageUri.isEmpty {
      try visitor.visitSingularStringField(value: self.executorImageUri, fieldNumber: 1)
    }
    if !self.packageUris.isEmpty {
      try visitor.visitRepeatedStringField(value: self.packageUris, fieldNumber: 2)
    }
    if !self.pythonModule.isEmpty {
      try visitor.visitSingularStringField(value: self.pythonModule, fieldNumber: 3)
    }
    if !self.args.isEmpty {
      try visitor.visitRepeatedStringField(value: self.args, fieldNumber: 4)
    }
    if !self.env.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.env, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_PythonPackageSpec, rhs: Google_Cloud_Aiplatform_V1_PythonPackageSpec) -> Bool {
    if lhs.executorImageUri != rhs.executorImageUri {return false}
    if lhs.packageUris != rhs.packageUris {return false}
    if lhs.pythonModule != rhs.pythonModule {return false}
    if lhs.args != rhs.args {return false}
    if lhs.env != rhs.env {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_Scheduling: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Scheduling"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "timeout"),
    3: .standard(proto: "restart_job_on_worker_restart"),
    4: .same(proto: "strategy"),
    5: .standard(proto: "disable_retries"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._timeout) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.restartJobOnWorkerRestart) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.strategy) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self.disableRetries) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._timeout {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.restartJobOnWorkerRestart != false {
      try visitor.visitSingularBoolField(value: self.restartJobOnWorkerRestart, fieldNumber: 3)
    }
    if self.strategy != .unspecified {
      try visitor.visitSingularEnumField(value: self.strategy, fieldNumber: 4)
    }
    if self.disableRetries != false {
      try visitor.visitSingularBoolField(value: self.disableRetries, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_Scheduling, rhs: Google_Cloud_Aiplatform_V1_Scheduling) -> Bool {
    if lhs._timeout != rhs._timeout {return false}
    if lhs.restartJobOnWorkerRestart != rhs.restartJobOnWorkerRestart {return false}
    if lhs.strategy != rhs.strategy {return false}
    if lhs.disableRetries != rhs.disableRetries {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_Scheduling.Strategy: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STRATEGY_UNSPECIFIED"),
    1: .same(proto: "ON_DEMAND"),
    2: .same(proto: "LOW_COST"),
    3: .same(proto: "STANDARD"),
    4: .same(proto: "SPOT"),
  ]
}
