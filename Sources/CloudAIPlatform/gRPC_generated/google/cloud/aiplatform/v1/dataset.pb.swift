// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/aiplatform/v1/dataset.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// A collection of DataItems and Annotations on them.
public struct Google_Cloud_Aiplatform_V1_Dataset: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Identifier. The resource name of the Dataset.
  public var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// Required. The user-defined name of the Dataset.
  /// The name can be up to 128 characters long and can consist of any UTF-8
  /// characters.
  public var displayName: String {
    get {return _storage._displayName}
    set {_uniqueStorage()._displayName = newValue}
  }

  /// The description of the Dataset.
  public var description_p: String {
    get {return _storage._description_p}
    set {_uniqueStorage()._description_p = newValue}
  }

  /// Required. Points to a YAML file stored on Google Cloud Storage describing
  /// additional information about the Dataset. The schema is defined as an
  /// OpenAPI 3.0.2 Schema Object. The schema files that can be used here are
  /// found in gs://google-cloud-aiplatform/schema/dataset/metadata/.
  public var metadataSchemaUri: String {
    get {return _storage._metadataSchemaUri}
    set {_uniqueStorage()._metadataSchemaUri = newValue}
  }

  /// Required. Additional information about the Dataset.
  public var metadata: SwiftProtobuf.Google_Protobuf_Value {
    get {return _storage._metadata ?? SwiftProtobuf.Google_Protobuf_Value()}
    set {_uniqueStorage()._metadata = newValue}
  }
  /// Returns true if `metadata` has been explicitly set.
  public var hasMetadata: Bool {return _storage._metadata != nil}
  /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
  public mutating func clearMetadata() {_uniqueStorage()._metadata = nil}

  /// Output only. The number of DataItems in this Dataset. Only apply for
  /// non-structured Dataset.
  public var dataItemCount: Int64 {
    get {return _storage._dataItemCount}
    set {_uniqueStorage()._dataItemCount = newValue}
  }

  /// Output only. Timestamp when this Dataset was created.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return _storage._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {_uniqueStorage()._createTime = nil}

  /// Output only. Timestamp when this Dataset was last updated.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// Used to perform consistent read-modify-write updates. If not set, a blind
  /// "overwrite" update happens.
  public var etag: String {
    get {return _storage._etag}
    set {_uniqueStorage()._etag = newValue}
  }

  /// The labels with user-defined metadata to organize your Datasets.
  ///
  /// Label keys and values can be no longer than 64 characters
  /// (Unicode codepoints), can only contain lowercase letters, numeric
  /// characters, underscores and dashes. International characters are allowed.
  /// No more than 64 user labels can be associated with one Dataset (System
  /// labels are excluded).
  ///
  /// See https://goo.gl/xmQnxf for more information and examples of labels.
  /// System reserved label keys are prefixed with "aiplatform.googleapis.com/"
  /// and are immutable. Following system labels exist for each Dataset:
  ///
  /// * "aiplatform.googleapis.com/dataset_metadata_schema": output only, its
  ///   value is the
  ///   [metadata_schema's][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri]
  ///   title.
  public var labels: Dictionary<String,String> {
    get {return _storage._labels}
    set {_uniqueStorage()._labels = newValue}
  }

  /// All SavedQueries belong to the Dataset will be returned in List/Get
  /// Dataset response. The annotation_specs field
  /// will not be populated except for UI cases which will only use
  /// [annotation_spec_count][google.cloud.aiplatform.v1.SavedQuery.annotation_spec_count].
  /// In CreateDataset request, a SavedQuery is created together if
  /// this field is set, up to one SavedQuery can be set in CreateDatasetRequest.
  /// The SavedQuery should not contain any AnnotationSpec.
  public var savedQueries: [Google_Cloud_Aiplatform_V1_SavedQuery] {
    get {return _storage._savedQueries}
    set {_uniqueStorage()._savedQueries = newValue}
  }

  /// Customer-managed encryption key spec for a Dataset. If set, this Dataset
  /// and all sub-resources of this Dataset will be secured by this key.
  public var encryptionSpec: Google_Cloud_Aiplatform_V1_EncryptionSpec {
    get {return _storage._encryptionSpec ?? Google_Cloud_Aiplatform_V1_EncryptionSpec()}
    set {_uniqueStorage()._encryptionSpec = newValue}
  }
  /// Returns true if `encryptionSpec` has been explicitly set.
  public var hasEncryptionSpec: Bool {return _storage._encryptionSpec != nil}
  /// Clears the value of `encryptionSpec`. Subsequent reads from it will return its default value.
  public mutating func clearEncryptionSpec() {_uniqueStorage()._encryptionSpec = nil}

  /// Output only. The resource name of the Artifact that was created in
  /// MetadataStore when creating the Dataset. The Artifact resource name pattern
  /// is
  /// `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
  public var metadataArtifact: String {
    get {return _storage._metadataArtifact}
    set {_uniqueStorage()._metadataArtifact = newValue}
  }

  /// Optional. Reference to the public base model last used by the dataset. Only
  /// set for prompt datasets.
  public var modelReference: String {
    get {return _storage._modelReference}
    set {_uniqueStorage()._modelReference = newValue}
  }

  /// Output only. Reserved for future use.
  public var satisfiesPzs: Bool {
    get {return _storage._satisfiesPzs}
    set {_uniqueStorage()._satisfiesPzs = newValue}
  }

  /// Output only. Reserved for future use.
  public var satisfiesPzi: Bool {
    get {return _storage._satisfiesPzi}
    set {_uniqueStorage()._satisfiesPzi = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Describes the location from where we import data into a Dataset, together
/// with the labels that will be applied to the DataItems and the Annotations.
public struct Google_Cloud_Aiplatform_V1_ImportDataConfig: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The source of the input.
  public var source: Google_Cloud_Aiplatform_V1_ImportDataConfig.OneOf_Source? = nil

  /// The Google Cloud Storage location for the input content.
  public var gcsSource: Google_Cloud_Aiplatform_V1_GcsSource {
    get {
      if case .gcsSource(let v)? = source {return v}
      return Google_Cloud_Aiplatform_V1_GcsSource()
    }
    set {source = .gcsSource(newValue)}
  }

  /// Labels that will be applied to newly imported DataItems. If an identical
  /// DataItem as one being imported already exists in the Dataset, then these
  /// labels will be appended to these of the already existing one, and if labels
  /// with identical key is imported before, the old label value will be
  /// overwritten. If two DataItems are identical in the same import data
  /// operation, the labels will be combined and if key collision happens in this
  /// case, one of the values will be picked randomly. Two DataItems are
  /// considered identical if their content bytes are identical (e.g. image bytes
  /// or pdf bytes).
  /// These labels will be overridden by Annotation labels specified inside index
  /// file referenced by
  /// [import_schema_uri][google.cloud.aiplatform.v1.ImportDataConfig.import_schema_uri],
  /// e.g. jsonl file.
  public var dataItemLabels: Dictionary<String,String> = [:]

  /// Labels that will be applied to newly imported Annotations. If two
  /// Annotations are identical, one of them will be deduped. Two Annotations are
  /// considered identical if their
  /// [payload][google.cloud.aiplatform.v1.Annotation.payload],
  /// [payload_schema_uri][google.cloud.aiplatform.v1.Annotation.payload_schema_uri]
  /// and all of their [labels][google.cloud.aiplatform.v1.Annotation.labels] are
  /// the same. These labels will be overridden by Annotation labels specified
  /// inside index file referenced by
  /// [import_schema_uri][google.cloud.aiplatform.v1.ImportDataConfig.import_schema_uri],
  /// e.g. jsonl file.
  public var annotationLabels: Dictionary<String,String> = [:]

  /// Required. Points to a YAML file stored on Google Cloud Storage describing
  /// the import format. Validation will be done against the schema. The schema
  /// is defined as an [OpenAPI 3.0.2 Schema
  /// Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
  public var importSchemaUri: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The source of the input.
  public enum OneOf_Source: Equatable, Sendable {
    /// The Google Cloud Storage location for the input content.
    case gcsSource(Google_Cloud_Aiplatform_V1_GcsSource)

  }

  public init() {}
}

/// Describes what part of the Dataset is to be exported, the destination of
/// the export and how to export.
public struct Google_Cloud_Aiplatform_V1_ExportDataConfig: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The destination of the output.
  public var destination: Google_Cloud_Aiplatform_V1_ExportDataConfig.OneOf_Destination? = nil

  /// The Google Cloud Storage location where the output is to be written to.
  /// In the given directory a new directory will be created with name:
  /// `export-data-<dataset-display-name>-<timestamp-of-export-call>` where
  /// timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All export
  /// output will be written into that directory. Inside that directory,
  /// annotations with the same schema will be grouped into sub directories
  /// which are named with the corresponding annotations' schema title. Inside
  /// these sub directories, a schema.yaml will be created to describe the
  /// output format.
  public var gcsDestination: Google_Cloud_Aiplatform_V1_GcsDestination {
    get {
      if case .gcsDestination(let v)? = destination {return v}
      return Google_Cloud_Aiplatform_V1_GcsDestination()
    }
    set {destination = .gcsDestination(newValue)}
  }

  /// The instructions how the export data should be split between the
  /// training, validation and test sets.
  public var split: Google_Cloud_Aiplatform_V1_ExportDataConfig.OneOf_Split? = nil

  /// Split based on fractions defining the size of each set.
  public var fractionSplit: Google_Cloud_Aiplatform_V1_ExportFractionSplit {
    get {
      if case .fractionSplit(let v)? = split {return v}
      return Google_Cloud_Aiplatform_V1_ExportFractionSplit()
    }
    set {split = .fractionSplit(newValue)}
  }

  /// Split based on the provided filters for each set.
  public var filterSplit: Google_Cloud_Aiplatform_V1_ExportFilterSplit {
    get {
      if case .filterSplit(let v)? = split {return v}
      return Google_Cloud_Aiplatform_V1_ExportFilterSplit()
    }
    set {split = .filterSplit(newValue)}
  }

  /// An expression for filtering what part of the Dataset is to be exported.
  /// Only Annotations that match this filter will be exported. The filter syntax
  /// is the same as in
  /// [ListAnnotations][google.cloud.aiplatform.v1.DatasetService.ListAnnotations].
  public var annotationsFilter: String = String()

  /// The ID of a SavedQuery (annotation set) under the Dataset specified by
  /// [dataset_id][] used for filtering Annotations for training.
  ///
  /// Only used for custom training data export use cases.
  /// Only applicable to Datasets that have SavedQueries.
  ///
  /// Only Annotations that are associated with this SavedQuery are used in
  /// respectively training. When used in conjunction with
  /// [annotations_filter][google.cloud.aiplatform.v1.ExportDataConfig.annotations_filter],
  /// the Annotations used for training are filtered by both
  /// [saved_query_id][google.cloud.aiplatform.v1.ExportDataConfig.saved_query_id]
  /// and
  /// [annotations_filter][google.cloud.aiplatform.v1.ExportDataConfig.annotations_filter].
  ///
  /// Only one of
  /// [saved_query_id][google.cloud.aiplatform.v1.ExportDataConfig.saved_query_id]
  /// and
  /// [annotation_schema_uri][google.cloud.aiplatform.v1.ExportDataConfig.annotation_schema_uri]
  /// should be specified as both of them represent the same thing: problem type.
  public var savedQueryID: String = String()

  /// The Cloud Storage URI that points to a YAML file describing the annotation
  /// schema. The schema is defined as an OpenAPI 3.0.2 [Schema
  /// Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
  /// The schema files that can be used here are found in
  /// gs://google-cloud-aiplatform/schema/dataset/annotation/, note that the
  /// chosen schema must be consistent with
  /// [metadata][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri] of the
  /// Dataset specified by [dataset_id][].
  ///
  /// Only used for custom training data export use cases.
  /// Only applicable to Datasets that have DataItems and Annotations.
  ///
  /// Only Annotations that both match this schema and belong to DataItems not
  /// ignored by the split method are used in respectively training, validation
  /// or test role, depending on the role of the DataItem they are on.
  ///
  /// When used in conjunction with
  /// [annotations_filter][google.cloud.aiplatform.v1.ExportDataConfig.annotations_filter],
  /// the Annotations used for training are filtered by both
  /// [annotations_filter][google.cloud.aiplatform.v1.ExportDataConfig.annotations_filter]
  /// and
  /// [annotation_schema_uri][google.cloud.aiplatform.v1.ExportDataConfig.annotation_schema_uri].
  public var annotationSchemaUri: String = String()

  /// Indicates the usage of the exported files.
  public var exportUse: Google_Cloud_Aiplatform_V1_ExportDataConfig.ExportUse = .unspecified

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The destination of the output.
  public enum OneOf_Destination: Equatable, Sendable {
    /// The Google Cloud Storage location where the output is to be written to.
    /// In the given directory a new directory will be created with name:
    /// `export-data-<dataset-display-name>-<timestamp-of-export-call>` where
    /// timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All export
    /// output will be written into that directory. Inside that directory,
    /// annotations with the same schema will be grouped into sub directories
    /// which are named with the corresponding annotations' schema title. Inside
    /// these sub directories, a schema.yaml will be created to describe the
    /// output format.
    case gcsDestination(Google_Cloud_Aiplatform_V1_GcsDestination)

  }

  /// The instructions how the export data should be split between the
  /// training, validation and test sets.
  public enum OneOf_Split: Equatable, Sendable {
    /// Split based on fractions defining the size of each set.
    case fractionSplit(Google_Cloud_Aiplatform_V1_ExportFractionSplit)
    /// Split based on the provided filters for each set.
    case filterSplit(Google_Cloud_Aiplatform_V1_ExportFilterSplit)

  }

  /// ExportUse indicates the usage of the exported files. It restricts file
  /// destination, format, annotations to be exported, whether to allow
  /// unannotated data to be exported and whether to clone files to temp Cloud
  /// Storage bucket.
  public enum ExportUse: SwiftProtobuf.Enum, Swift.CaseIterable {
    public typealias RawValue = Int

    /// Regular user export.
    case unspecified // = 0

    /// Export for custom code training.
    case customCodeTraining // = 6
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 6: self = .customCodeTraining
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .customCodeTraining: return 6
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    public static let allCases: [Google_Cloud_Aiplatform_V1_ExportDataConfig.ExportUse] = [
      .unspecified,
      .customCodeTraining,
    ]

  }

  public init() {}
}

/// Assigns the input data to training, validation, and test sets as per the
/// given fractions. Any of `training_fraction`, `validation_fraction` and
/// `test_fraction` may optionally be provided, they must sum to up to 1. If the
/// provided ones sum to less than 1, the remainder is assigned to sets as
/// decided by Vertex AI. If none of the fractions are set, by default roughly
/// 80% of data is used for training, 10% for validation, and 10% for test.
public struct Google_Cloud_Aiplatform_V1_ExportFractionSplit: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The fraction of the input data that is to be used to train the Model.
  public var trainingFraction: Double = 0

  /// The fraction of the input data that is to be used to validate the Model.
  public var validationFraction: Double = 0

  /// The fraction of the input data that is to be used to evaluate the Model.
  public var testFraction: Double = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Assigns input data to training, validation, and test sets based on the given
/// filters, data pieces not matched by any filter are ignored. Currently only
/// supported for Datasets containing DataItems.
/// If any of the filters in this message are to match nothing, then they can be
/// set as '-' (the minus sign).
///
/// Supported only for unstructured Datasets.
public struct Google_Cloud_Aiplatform_V1_ExportFilterSplit: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. A filter on DataItems of the Dataset. DataItems that match
  /// this filter are used to train the Model. A filter with same syntax
  /// as the one used in
  /// [DatasetService.ListDataItems][google.cloud.aiplatform.v1.DatasetService.ListDataItems]
  /// may be used. If a single DataItem is matched by more than one of the
  /// FilterSplit filters, then it is assigned to the first set that applies to
  /// it in the training, validation, test order.
  public var trainingFilter: String = String()

  /// Required. A filter on DataItems of the Dataset. DataItems that match
  /// this filter are used to validate the Model. A filter with same syntax
  /// as the one used in
  /// [DatasetService.ListDataItems][google.cloud.aiplatform.v1.DatasetService.ListDataItems]
  /// may be used. If a single DataItem is matched by more than one of the
  /// FilterSplit filters, then it is assigned to the first set that applies to
  /// it in the training, validation, test order.
  public var validationFilter: String = String()

  /// Required. A filter on DataItems of the Dataset. DataItems that match
  /// this filter are used to test the Model. A filter with same syntax
  /// as the one used in
  /// [DatasetService.ListDataItems][google.cloud.aiplatform.v1.DatasetService.ListDataItems]
  /// may be used. If a single DataItem is matched by more than one of the
  /// FilterSplit filters, then it is assigned to the first set that applies to
  /// it in the training, validation, test order.
  public var testFilter: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.aiplatform.v1"

extension Google_Cloud_Aiplatform_V1_Dataset: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Dataset"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "display_name"),
    16: .same(proto: "description"),
    3: .standard(proto: "metadata_schema_uri"),
    8: .same(proto: "metadata"),
    10: .standard(proto: "data_item_count"),
    4: .standard(proto: "create_time"),
    5: .standard(proto: "update_time"),
    6: .same(proto: "etag"),
    7: .same(proto: "labels"),
    9: .standard(proto: "saved_queries"),
    11: .standard(proto: "encryption_spec"),
    17: .standard(proto: "metadata_artifact"),
    18: .standard(proto: "model_reference"),
    19: .standard(proto: "satisfies_pzs"),
    20: .standard(proto: "satisfies_pzi"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _displayName: String = String()
    var _description_p: String = String()
    var _metadataSchemaUri: String = String()
    var _metadata: SwiftProtobuf.Google_Protobuf_Value? = nil
    var _dataItemCount: Int64 = 0
    var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _etag: String = String()
    var _labels: Dictionary<String,String> = [:]
    var _savedQueries: [Google_Cloud_Aiplatform_V1_SavedQuery] = []
    var _encryptionSpec: Google_Cloud_Aiplatform_V1_EncryptionSpec? = nil
    var _metadataArtifact: String = String()
    var _modelReference: String = String()
    var _satisfiesPzs: Bool = false
    var _satisfiesPzi: Bool = false

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _displayName = source._displayName
      _description_p = source._description_p
      _metadataSchemaUri = source._metadataSchemaUri
      _metadata = source._metadata
      _dataItemCount = source._dataItemCount
      _createTime = source._createTime
      _updateTime = source._updateTime
      _etag = source._etag
      _labels = source._labels
      _savedQueries = source._savedQueries
      _encryptionSpec = source._encryptionSpec
      _metadataArtifact = source._metadataArtifact
      _modelReference = source._modelReference
      _satisfiesPzs = source._satisfiesPzs
      _satisfiesPzi = source._satisfiesPzi
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._displayName) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._metadataSchemaUri) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._createTime) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 6: try { try decoder.decodeSingularStringField(value: &_storage._etag) }()
        case 7: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._labels) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._metadata) }()
        case 9: try { try decoder.decodeRepeatedMessageField(value: &_storage._savedQueries) }()
        case 10: try { try decoder.decodeSingularInt64Field(value: &_storage._dataItemCount) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._encryptionSpec) }()
        case 16: try { try decoder.decodeSingularStringField(value: &_storage._description_p) }()
        case 17: try { try decoder.decodeSingularStringField(value: &_storage._metadataArtifact) }()
        case 18: try { try decoder.decodeSingularStringField(value: &_storage._modelReference) }()
        case 19: try { try decoder.decodeSingularBoolField(value: &_storage._satisfiesPzs) }()
        case 20: try { try decoder.decodeSingularBoolField(value: &_storage._satisfiesPzi) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if !_storage._displayName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._displayName, fieldNumber: 2)
      }
      if !_storage._metadataSchemaUri.isEmpty {
        try visitor.visitSingularStringField(value: _storage._metadataSchemaUri, fieldNumber: 3)
      }
      try { if let v = _storage._createTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      if !_storage._etag.isEmpty {
        try visitor.visitSingularStringField(value: _storage._etag, fieldNumber: 6)
      }
      if !_storage._labels.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._labels, fieldNumber: 7)
      }
      try { if let v = _storage._metadata {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      if !_storage._savedQueries.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._savedQueries, fieldNumber: 9)
      }
      if _storage._dataItemCount != 0 {
        try visitor.visitSingularInt64Field(value: _storage._dataItemCount, fieldNumber: 10)
      }
      try { if let v = _storage._encryptionSpec {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      if !_storage._description_p.isEmpty {
        try visitor.visitSingularStringField(value: _storage._description_p, fieldNumber: 16)
      }
      if !_storage._metadataArtifact.isEmpty {
        try visitor.visitSingularStringField(value: _storage._metadataArtifact, fieldNumber: 17)
      }
      if !_storage._modelReference.isEmpty {
        try visitor.visitSingularStringField(value: _storage._modelReference, fieldNumber: 18)
      }
      if _storage._satisfiesPzs != false {
        try visitor.visitSingularBoolField(value: _storage._satisfiesPzs, fieldNumber: 19)
      }
      if _storage._satisfiesPzi != false {
        try visitor.visitSingularBoolField(value: _storage._satisfiesPzi, fieldNumber: 20)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_Dataset, rhs: Google_Cloud_Aiplatform_V1_Dataset) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._name != rhs_storage._name {return false}
        if _storage._displayName != rhs_storage._displayName {return false}
        if _storage._description_p != rhs_storage._description_p {return false}
        if _storage._metadataSchemaUri != rhs_storage._metadataSchemaUri {return false}
        if _storage._metadata != rhs_storage._metadata {return false}
        if _storage._dataItemCount != rhs_storage._dataItemCount {return false}
        if _storage._createTime != rhs_storage._createTime {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._etag != rhs_storage._etag {return false}
        if _storage._labels != rhs_storage._labels {return false}
        if _storage._savedQueries != rhs_storage._savedQueries {return false}
        if _storage._encryptionSpec != rhs_storage._encryptionSpec {return false}
        if _storage._metadataArtifact != rhs_storage._metadataArtifact {return false}
        if _storage._modelReference != rhs_storage._modelReference {return false}
        if _storage._satisfiesPzs != rhs_storage._satisfiesPzs {return false}
        if _storage._satisfiesPzi != rhs_storage._satisfiesPzi {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_ImportDataConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ImportDataConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "gcs_source"),
    2: .standard(proto: "data_item_labels"),
    3: .standard(proto: "annotation_labels"),
    4: .standard(proto: "import_schema_uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Google_Cloud_Aiplatform_V1_GcsSource?
        var hadOneofValue = false
        if let current = self.source {
          hadOneofValue = true
          if case .gcsSource(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.source = .gcsSource(v)
        }
      }()
      case 2: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.dataItemLabels) }()
      case 3: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.annotationLabels) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.importSchemaUri) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if case .gcsSource(let v)? = self.source {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.dataItemLabels.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.dataItemLabels, fieldNumber: 2)
    }
    if !self.annotationLabels.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.annotationLabels, fieldNumber: 3)
    }
    if !self.importSchemaUri.isEmpty {
      try visitor.visitSingularStringField(value: self.importSchemaUri, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_ImportDataConfig, rhs: Google_Cloud_Aiplatform_V1_ImportDataConfig) -> Bool {
    if lhs.source != rhs.source {return false}
    if lhs.dataItemLabels != rhs.dataItemLabels {return false}
    if lhs.annotationLabels != rhs.annotationLabels {return false}
    if lhs.importSchemaUri != rhs.importSchemaUri {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_ExportDataConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ExportDataConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "gcs_destination"),
    5: .standard(proto: "fraction_split"),
    7: .standard(proto: "filter_split"),
    2: .standard(proto: "annotations_filter"),
    11: .standard(proto: "saved_query_id"),
    12: .standard(proto: "annotation_schema_uri"),
    4: .standard(proto: "export_use"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Google_Cloud_Aiplatform_V1_GcsDestination?
        var hadOneofValue = false
        if let current = self.destination {
          hadOneofValue = true
          if case .gcsDestination(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.destination = .gcsDestination(v)
        }
      }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.annotationsFilter) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.exportUse) }()
      case 5: try {
        var v: Google_Cloud_Aiplatform_V1_ExportFractionSplit?
        var hadOneofValue = false
        if let current = self.split {
          hadOneofValue = true
          if case .fractionSplit(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.split = .fractionSplit(v)
        }
      }()
      case 7: try {
        var v: Google_Cloud_Aiplatform_V1_ExportFilterSplit?
        var hadOneofValue = false
        if let current = self.split {
          hadOneofValue = true
          if case .filterSplit(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.split = .filterSplit(v)
        }
      }()
      case 11: try { try decoder.decodeSingularStringField(value: &self.savedQueryID) }()
      case 12: try { try decoder.decodeSingularStringField(value: &self.annotationSchemaUri) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if case .gcsDestination(let v)? = self.destination {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.annotationsFilter.isEmpty {
      try visitor.visitSingularStringField(value: self.annotationsFilter, fieldNumber: 2)
    }
    if self.exportUse != .unspecified {
      try visitor.visitSingularEnumField(value: self.exportUse, fieldNumber: 4)
    }
    switch self.split {
    case .fractionSplit?: try {
      guard case .fractionSplit(let v)? = self.split else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .filterSplit?: try {
      guard case .filterSplit(let v)? = self.split else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }()
    case nil: break
    }
    if !self.savedQueryID.isEmpty {
      try visitor.visitSingularStringField(value: self.savedQueryID, fieldNumber: 11)
    }
    if !self.annotationSchemaUri.isEmpty {
      try visitor.visitSingularStringField(value: self.annotationSchemaUri, fieldNumber: 12)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_ExportDataConfig, rhs: Google_Cloud_Aiplatform_V1_ExportDataConfig) -> Bool {
    if lhs.destination != rhs.destination {return false}
    if lhs.split != rhs.split {return false}
    if lhs.annotationsFilter != rhs.annotationsFilter {return false}
    if lhs.savedQueryID != rhs.savedQueryID {return false}
    if lhs.annotationSchemaUri != rhs.annotationSchemaUri {return false}
    if lhs.exportUse != rhs.exportUse {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_ExportDataConfig.ExportUse: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "EXPORT_USE_UNSPECIFIED"),
    6: .same(proto: "CUSTOM_CODE_TRAINING"),
  ]
}

extension Google_Cloud_Aiplatform_V1_ExportFractionSplit: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ExportFractionSplit"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "training_fraction"),
    2: .standard(proto: "validation_fraction"),
    3: .standard(proto: "test_fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularDoubleField(value: &self.trainingFraction) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.validationFraction) }()
      case 3: try { try decoder.decodeSingularDoubleField(value: &self.testFraction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.trainingFraction.bitPattern != 0 {
      try visitor.visitSingularDoubleField(value: self.trainingFraction, fieldNumber: 1)
    }
    if self.validationFraction.bitPattern != 0 {
      try visitor.visitSingularDoubleField(value: self.validationFraction, fieldNumber: 2)
    }
    if self.testFraction.bitPattern != 0 {
      try visitor.visitSingularDoubleField(value: self.testFraction, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_ExportFractionSplit, rhs: Google_Cloud_Aiplatform_V1_ExportFractionSplit) -> Bool {
    if lhs.trainingFraction != rhs.trainingFraction {return false}
    if lhs.validationFraction != rhs.validationFraction {return false}
    if lhs.testFraction != rhs.testFraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Aiplatform_V1_ExportFilterSplit: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ExportFilterSplit"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "training_filter"),
    2: .standard(proto: "validation_filter"),
    3: .standard(proto: "test_filter"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.trainingFilter) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.validationFilter) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.testFilter) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.trainingFilter.isEmpty {
      try visitor.visitSingularStringField(value: self.trainingFilter, fieldNumber: 1)
    }
    if !self.validationFilter.isEmpty {
      try visitor.visitSingularStringField(value: self.validationFilter, fieldNumber: 2)
    }
    if !self.testFilter.isEmpty {
      try visitor.visitSingularStringField(value: self.testFilter, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Aiplatform_V1_ExportFilterSplit, rhs: Google_Cloud_Aiplatform_V1_ExportFilterSplit) -> Bool {
    if lhs.trainingFilter != rhs.trainingFilter {return false}
    if lhs.validationFilter != rhs.validationFilter {return false}
    if lhs.testFilter != rhs.testFilter {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
